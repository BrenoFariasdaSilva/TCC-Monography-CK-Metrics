%%%% CAPÍTULO 5 - Metodologia

\chapter{Metodologia}\label{cap:Metodologia}

\section{Questões de pesquisa}
As questões de pesquisa foram formuladas com base nos objetivos geral e específicos desta monografia. Elas direcionarão a investigação sobre a evolução do código em \gls{sds} por meio da análise de métricas de código, de modo a criar um exemplo trabalhado para a \gls{es}.

\begin{enumerate}
    \item Como identificar métricas de código relevantes para a análise da evolução em \gls{sds}?
    
    \item Quais são os padrões e tendências observados que correspondem a uma melhoria do código em \gls{sds}?
    
    \item De que maneira as métricas selecionadas refletem em melhorias com relação a, por exemplo, desempenho e segurança do código em \gls{sds}?
    
    \item Como transformar um código selecionado pela melhoria das métricas selecionadas de modo a criar um exemplo trabalhado que ilustre a evolução do código em \gls{sds} para o ensino de \gls{es}?
\end{enumerate}

\section{Abordagem proposta}

\section{Ferramentas}\label{sec:ferramentas}
O \gls{ck} \cite{aniche-ck} é uma ferramenta poderosa que nos permite analisar a qualidade do código-fonte em projetos Java por meio da análise de métricas estáticas de código. Essas métricas fornecem informações valiosas sobre características como complexidade, acoplamento e coesão de classes. Ao incorporar o \gls{ck} em nossa pesquisa, estamos criando formas de classificar classes ou métodos com relação a métricas estáticas de qualidade de código. A ferramenta em questão apresenta mais de 35 métricas.

O RefactoringMiner \cite{Tsantalis:ICSE:2018:RefactoringMiner} é uma ferramenta fundamental no contexto da \gls{es}, especializada em identificar e analisar refatorações de código-fonte. Essa ferramenta desempenha um papel crucial ao fornecer uma compreensão aprofundada das mudanças realizadas em um código ao longo do tempo. Com a sua capacidade de reconhecer padrões de refatoração, o RefactoringMiner permite que os desenvolvedores analisem como o código foi modificado, de modo a melhorar a qualidade, manutenibilidade e eficiência do software.

A biblioteca PyDriller \cite{PyDrillerSpadini2018} é um recurso essencial para análise de repositórios de código-fonte escritos em Python. Sua funcionalidade abrangente permite aos pesquisadores e desenvolvedores explorar e compreender a evolução do código em projetos Python de uma maneira eficiente. O PyDriller oferece recursos para extrair informações cruciais, como histórico, autoria e mensagens de \textit{commits}, além de detalhes específicos do estado do código em um determinado momento, contribuindo assim para a pesquisa e prática em \gls{es} no contexto de sistemas complexos e interconectados.

OBS: Pedir ajuda com a repetição da palavra ``código''.

\section{Repositórios}\label{sec:repositorios}
O Apache Kafka \cite{KafkaGitHub} é um sistema de mensagens distribuídas, baseado no modelo \textit{publish-subscribe}, que desempenha um papel fundamental na infraestrutura de processamento de eventos em tempo real. Conforme o artigo ``Apache Kafka: Next Generation Distributed Messaging System'' \cite{ApacheKafkaNextGenerationDistributedMessagingSystem:2010}, o Kafka é projetado para lidar com fluxos de dados em grande escala, permitindo que organizações processem, armazenem e transmitam dados de maneira eficiente, o qual opera em um modelo de log distribuído, no qual as mensagens são registradas em logs (ou tópicos) que podem ser divididos em partições. 
A estrutura do Apache Kafka é composta por vários componentes, incluindo:

\begin{itemize}
  \item \textbf{Produtores}: São responsáveis por publicar mensagens em tópicos do Kafka.
  \item \textbf{Tópicos}: São canais de mensagens nos quais os dados são publicados e armazenados.
  \item \textbf{Partições}: Os tópicos podem ser divididos em partições para permitir a distribuição e o processamento paralelo de mensagens.
  \item \textbf{Corretores (Brokers)}: São servidores que armazenam e distribuem as mensagens. Eles desempenham um papel central na arquitetura do Kafka.
  \item \textbf{Consumidores}: São aplicativos que se inscrevem nos tópicos para receber mensagens e processá-las.
  \item \textbf{\gls{zk} (KRaft em 2023)}: No passado, o Kafka dependia do Apache \gls{zk} para gerenciamento de metadados e coordenação. No entanto, em 2023, o Kafka adotou o KRaft como substituto, eliminando a dependência do \gls{zk}, com o intuito de deixá-lo mais simples e robusto.
\end{itemize}
Isso permite a escalabilidade, tolerância a falhas e a distribuição das mensagens em várias máquinas e servidores, tornando-o uma escolha popular em empresas como LinkedIn, Twitter, Foursquare, entre outros para a construção de pipelines de dados em tempo real e sistemas de processamento de eventos.

O \gls{zk} \cite{ZookeeperGitHub} é um serviço de coordenação distribuída amplamente utilizado para sistemas de grande escala na internet. Ele fornece um ambiente confiável e altamente disponível para a coordenação de tarefas entre diversos nós em um cluster distribuído. Na ótica do artigo ``ZooKeeper: Wait-free coordination for Internet-scale systems'' \cite{ZooKeeperWaitFree:2010}, o \gls{zk} é baseado em um conjunto de servidores distribuídos que formam um conjunto chamado ``\textit{ensemble}''. Cada servidor nesse conjunto mantém uma cópia completa dos dados de configuração e estado do sistema. Os clientes se conectam a qualquer servidor do conjunto e podem ler ou gravar informações. Quando os clientes gravam informações, elas são replicadas para a maioria dos servidores no conjunto antes de serem confirmadas, garantindo assim a consistência dos dados. 

O \gls{zk} fornece um sistema de coordenação sem espera (do inglês, ``\textit{wait-free}''), por meio de um mecanismo de observação para permitir que os clientes armazenem dados em \textit{cache} sem ter que gerenciar o \textit{cache} do cliente diretamente. Além disso, a implementação do algoritmo denominado \gls{zab} é responsável por garantir a consistência de dados distribuídos no \gls{zk} por meio do uso do \textit{Two-Phase Commit Protocol} para replicar todas as transações para todos os nós do cluster do \gls{zk}\cite{CloudKarafkaZAB}.

\section{Métodos}\label{sec:metodo}

\section{Resultados esperados e cronograma}

\begin{itemize}
    \item Realizar uma revisão da literatura abrangente, explorando estudos relevantes em \gls{sds} e métricas de código em \gls{es}.
    \\\textbf{Resultado esperado:} Lista de estudos sobre exemplos trabalhados e as respectivas contribuições.
    
    \item Selecionar exemplos específicos de código trabalhados nos repositórios escolhidos, aplicando a heurística desenvolvida e justificando a seleção com base em métricas de código. OBS: Passo dos materiais e métodos.
    \\\textbf{Resultado esperado:}
    
    \item Avaliar a utilidade educacional dos exemplos de código selecionados, usando-os em um contexto de ensino. OBS: Passo dos materiais e métodos
    \\\textbf{Resultado esperado:}
    
    \item Selecionar métricas de código específicas e relevantes apropriadas para avaliar a evolução de código em \gls{sds}, considerando as melhores práticas da área. OBS: Parece um passo.
    \\\textbf{Resultado esperado:}
    
    \item Selecionar um ou mais repositórios \textit{open-source} pertinentes à área de \gls{sds} que servirão como fonte de exemplos de código para análise.
\end{itemize}