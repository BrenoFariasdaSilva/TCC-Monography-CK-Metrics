\chapter{Resultados}
\label{chapter:results}

% Seleção de Projetos.
\section{Seleção de projetos}

% Critérios de seleção de repositórios.
Os critérios para a seleção de repositórios foram determinados pelos seguintes fatores:

\begin{itemize}
    \item \textbf{Ser um repositório Java:} Essencial para viabilizar a aplicação das métricas \gls{ck}.
    \item \textbf{Ser de código aberto (\textit{open-source}):} A escolha por repositórios abertos, hospedados em plataformas como o \textit{Github}, visa garantir a transparência e acessibilidade do código-fonte.
    \item \textbf{Ser ativamente mantido e atualizado:} A ativa manutenção é crucial para garantir que os repositórios estejam alinhados com as práticas e avanços mais recentes.
    \item \textbf{Ser utilizado em aplicações do mundo real:} A seleção de repositórios empregados em contextos práticos proporciona uma análise mais relevante e aplicável às situações reais.
\end{itemize}

Dessa forma, os repositórios escolhidos foram o Apache Kafka e o ZooKeeper. Essa escolha baseou-se no fato de ambos os repositórios serem projetos \textit{open-source} disponíveis na plataforma GitHub, onde ambos são mantidos e atualizados de forma ativa para serem utilizados em ambientes do mundo real. Além disso, esses projetos lidam com questões altamente relevantes em \gls{sds}.

O ZooKeeper desempenha um papel fundamental na coordenação e gerenciamento de serviços distribuídos. Ele oferece um serviço de consenso altamente confiável para \gls{sds}, garantindo a consistência e a sincronização entre os nós. Essa funcionalidade é crucial para a implementação de serviços distribuídos confiáveis e escaláveis, tornando o ZooKeeper uma escolha valiosa para este estudo.

Por outro lado, o Apache Kafka destaca-se no processamento de fluxos de dados distribuídos em larga escala. Ele fornece uma plataforma robusta para a transmissão eficiente de eventos entre diferentes componentes de um \gls{sd}. A capacidade do Kafka lidar com volumes massivos de dados em tempo real o torna uma solução amplamente adotada em ambientes que demandam alto desempenho e escalabilidade.

Dessa forma, o ambos os repositórios têm muito a agregar em termos de implementação e evolução tanto para a área de \gls{sds} quanto para a \gls{es}. Assim, a escolha desses repositórios permite a análise da evolução do código em contextos práticos e desafiadores, contribuindo para uma compreensão mais abrangente das práticas de desenvolvimento em \gls{sds}.

% Desenvolvimento da ferramenta.
\section{Desenvolvimento da ferramenta}
% Talk about PyDriller, RefactoringMiner Scientific Research Codes.
A \href{https://github.com/BrenoFariasdaSilva/Scientific-Research/blob/main/PyDriller/metrics_changes.py}{primeira ferramenta} desenvolvida está integrada ao \textit{PyDriller} e ao \gls{ck}. Durante esse processo, a ferramenta percorre toda a árvore de \textit{commits} de um repositório específico. Para cada \textit{commit}, o \gls{ck} é executado, resultando na geração das métricas \gls{ck} para cada estado do repositório ao final da execução. Adicionalmente, a ferramenta produz um \textit{diff} para cada refatoração realizada no repositório, possibilitando a investigação das refatorações realizadas no código em caso de identificação de uma tendência de melhoria das métricas.

A \href{https://github.com/BrenoFariasdaSilva/Scientific-Research/blob/main/PyDriller/metrics_changes.py}{segunda ferramenta} desenvolvida depende da execução do primeiro código para operar. Essencialmente, esta ferramenta percorre as métricas de todos os estados do repositório processado, produzindo os seguintes resultados:

\begin{itemize}
    \item \textbf{Evolução das métricas}: Geração de arquivos divididos por classe e métodos, contendo o histórico completo de alterações em cada classe ou método, incluindo suas métricas correspondentes.
    \item \textbf{Predição das métricas}: Criação de arquivos segmentados por classe e métodos, apresentando uma predição baseada na regressão linear aplicada às métricas analisadas, utilizando o histórico gerado anteriormente.
    \item \textbf{Estatísticas das métricas}: Produção de um arquivo para classes e outro para métodos, ordenados pelo número de alterações efetuadas em cada classe ou método.
    \item \textbf{Alterações substanciais nas métricas}: Geração de arquivos para classes e métodos, ordenados pela queda percentual dos valores da métrica \gls{cbo} em cada classe ou método.
\end{itemize}

Assim, resumidamente, esse código gera metadados que facilitam a análise dos códigos, reduzindo o escopo de busca por refatorações que, à luz das métricas, são consideradas relevantes para nosso estudo.

A \href{https://github.com/BrenoFariasdaSilva/Scientific-Research/blob/main/PyDriller/Scripts/track_files.py}{terceira ferramenta} desenvolvida, mais uma vez, depende da execução do primeiro código para funcionar. Em suma, esta ferramenta busca por arquivos específicos nos \textit{diffs} dos repositórios. Em nosso estudo, foi utilizada para localizar arquivos de comentários sobre as refatorações realizadas em um \textit{commit}, como o arquivo ``CHANGES.txt'', uma vez que o espaço da mensagem do commit pode oferecer uma visão limitada das refatorações efetuadas.

A \href{https://github.com/BrenoFariasdaSilva/Scientific-Research/blob/main/PyDriller/Scripts/track_files.py}{quarta ferramenta} e a \href{https://github.com/BrenoFariasdaSilva/Scientific-Research/blob/main/RefactoringMiner/metrics_evolution_refactors.py}{quinta ferramenta} desenvolvidas são substancialmente similares, distinguindo-se apenas no escopo de aplicação, onde a quarta  incide sobre a totalidade do repositório, enquanto a quinta é específica para classes ou métodos dentro do repositório. Ambas as ferramentas compartilham um funcionamento comum, fazendo uso da ferramenta \textit{RefactoringMiner}.

O processo inicia-se com a utilização da ferramenta \textit{RefactoringMiner}, a qual, por meio da extração do histórico de \textit{commits}, analisa os \textit{diffs}, identificando padrões de refatorações. O \textit{RefactoringMiner} possui um banco de dados de refatorações previamente detectadas, permitindo uma análise eficiente das mudanças no código-fonte. A ferramenta gera uma saída estruturada que lista as refatorações identificadas, indicando quais arquivos e linhas de código foram afetados em cada \textit{commit}.

Essa saída estruturada proporciona uma base sólida para análises mais aprofundadas, permitindo uma compreensão detalhada das refatorações realizadas ao longo do tempo. A capacidade de distinguir entre o repositório inteiro (quarta ferramenta) e componentes específicos, como classes ou métodos (quinta ferramenta), amplia a flexibilidade dessas ferramentas, adaptando-as às necessidades específicas de investigação e análise de refatorações em projetos de software.

As ferramentas desenvolvidas podem ser encontradas \href{https://github.com/BrenoFariasdaSilva/Scientific-Research}{aqui}, estando as três primeiras no diretório ``PyDriller'' e as duas últimas no diretório ``RefactoringMiner''.

% Análise das métricas dos projetos selecionados.
\section{Análise das métricas dos projetos selecionados}
% Mencionar o caso de melhorias de performance do ZooKeeper, onde o commit altera inúmeros arquivos mas em si é apenas uma atualização da biblioteca, a qual existe desde o java 1.0 que foi lançado em torno de 1996.

\section{Limitações}
\label{sec:limitacoes}

% Limitações do projeto de pesquisa.
Este trabalho apresenta uma limitação, a qual reside na impossibilidade de realizar análises empíricas de certas melhorias de desempenho, como a análise das trocas de mensagens em tempo real, devido à restrição ao uso de métricas estáticas de código. Isso impede a avaliação prática por meio da execução de \gls{sds} e simulações em grande escala, representando uma restrição na obtenção de percepções detalhadas sobre o desempenho em contextos de uma quantidade massiva de requisições sendo enviadas ao \gls{sd}.